[package]
name = "peak-intelligence"
version = "0.1.0"
edition = "2021"

[dependencies]
tokio = { version = "1.38", features = ["full", "fs", "io-util", "process", "time"] }
serde = { version = "1", features = ["derive"] }
serde_json = "1"
anyhow = "1"
sysinfo = "0.30"
tracing = "0.1"
tracing-subscriber = "0.3"
reqwest = { version = "0.12", features = ["json", "rustls-tls", "socks", "gzip"] }

once_cell = "1.18"
portable-pty = "0.8"
walkdir = "2.4"

# Icebreaker Core Dependencies
decoder = "0.0.3"
directories = "6.0"
function = "0.2"
futures = "0.3"
log = "0.4"
scraper = "0.22"
sipper = "0.1"
thiserror = "1.0"
toml = "0.9"
chrono = { version = "0.4", features = ["serde"] }
tokio-stream = { version = "0.1", features = ["io-util"] }
url = { version = "2.5", features = ["serde"] }
uuid = { version = "1.10", features = ["v4", "serde"] }

# Git Dependency (Optional - causes issues on Alpine/musl)
llama-server = { git = "https://github.com/hecrj/llama-server.git", rev = "e7e016577ce11ff419628f5eca23732949990894", optional = true }

# Voice Integration (Optional)
whisper-rs = { version = "0.13", optional = true }
tts = { version = "0.26", optional = true }
cpal = { version = "0.15", optional = true }

[features]
default = ["llm"]
llm = ["llama-server"]
voice = ["whisper-rs", "tts", "cpal"]
